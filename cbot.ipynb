{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# English, French, Hindi Translator Chatbot using pre-trained model using Hugging Face Transformers library\n",
    "\n",
    "# Import required libraries\n",
    "from transformers import pipeline, AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "#import torch\n",
    "#import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Path for en, fr, hi model\n",
    "en_fr_model_path = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "fr_en_model_path = \"Helsinki-NLP/opus-mt-fr-en\"\n",
    "en_hi_model_path = \"Helsinki-NLP/opus-mt-en-hi\"\n",
    "hi_en_model_path = \"Helsinki-NLP/opus-mt-hi-en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained tokenizer\n",
    "en_fr_tokenizer = AutoTokenizer.from_pretrained(en_fr_model_path)\n",
    "fr_en_tokenizer = AutoTokenizer.from_pretrained(fr_en_model_path)\n",
    "en_hi_tokenizer = AutoTokenizer.from_pretrained(en_hi_model_path)\n",
    "hi_en_tokenizer = AutoTokenizer.from_pretrained(hi_en_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained models for en, fr, hi languages\n",
    "en_fr_model = AutoModelForSeq2SeqLM.from_pretrained(en_fr_model_path)\n",
    "fr_en_model = AutoModelForSeq2SeqLM.from_pretrained(fr_en_model_path)\n",
    "en_hi_model = AutoModelForSeq2SeqLM.from_pretrained(en_hi_model_path)\n",
    "hi_en_model = AutoModelForSeq2SeqLM.from_pretrained(hi_en_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create translation class\n",
    "\n",
    "class TranslatorBot:\n",
    "    def __init__(self):\n",
    "        self.translator = {}\n",
    "        self.translator['en_fr'] = pipeline(\"translation_en_to_fr\", model=en_fr_model, tokenizer=en_fr_tokenizer)\n",
    "        self.translator['fr_en'] = pipeline(\"translation_fr_to_en\", model=fr_en_model, tokenizer=fr_en_tokenizer)\n",
    "        self.translator['en_hi'] = pipeline(\"translation_en_to_hi\", model=en_hi_model, tokenizer=en_hi_tokenizer)\n",
    "        self.translator['hi_en'] = pipeline(\"translation_hi_to_en\", model=hi_en_model, tokenizer=hi_en_tokenizer)\n",
    "        \n",
    "    def translate(self, text, source_lang, target_lang):\n",
    "        if source_lang == target_lang:\n",
    "            return text\n",
    "        \n",
    "        translator = self.translator.get(f'{source_lang}_{target_lang}')\n",
    "        if translator is None:\n",
    "            return f'Sorry, I don\\'t support {source_lang}_{target_lang} translation.'\n",
    "        \n",
    "        return translator(text, max_length=400)[0]['translation_text']\n",
    "\n",
    "# Include argument device=0 in pipeline function to run torch library on GPU\n",
    "\n",
    "# You can also use following line of code for direct use of pre-trained model pipelines\n",
    "#en_fr_translator = pipeline(\"translation_en_to_fr\")\n",
    "#fr_en_translator = pipeline(\"translation_fr_to_en\")\n",
    "#en_hi_translator = pipeline(\"translation_en_to_hi\")\n",
    "#hi_en_translator = pipeline(\"translation_hi_to_en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the greeting messages for the chatbot\n",
    "#greetings = [\"Hello! I'm a language translator chatbot. How can I help you today?\",\n",
    "#             \"Hi there! I can translate between English, French, and Hindi. What do you need translated?\",\n",
    "#             \"Greetings! What can I do for you today?\"]\n",
    "\n",
    "# Define the goodbye messages for the chatbot\n",
    "#goodbyes = [\"Goodbye! Have a great day!\",\n",
    "#            \"See you later!\",\n",
    "#            \"Take care!\"]\n",
    "\n",
    "# Define a function to generate a random greeting message\n",
    "#def get_greeting():\n",
    "#    return random.choice(greetings)\n",
    "\n",
    "# Define a function to generate a random goodbye message\n",
    "#def get_goodbye():\n",
    "#    return random.choice(goodbyes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to translate text from one language to another\n",
    "#def translate(text, source_lang, target_lang):\n",
    "#    if source_lang == \"en\" and target_lang == \"fr\":\n",
    "#        return en_fr_translator(text, max_length=100)[0]['translation_text']\n",
    "#    elif source_lang == \"fr\" and target_lang == \"en\":\n",
    "#        return fr_en_translator(text, max_length=100)[0]['translation_text']\n",
    "#    elif source_lang == \"en\" and target_lang == \"hi\":\n",
    "#        return en_hi_translator(text, max_length=100)[0]['translation_text']\n",
    "#    elif source_lang == \"hi\" and target_lang == \"en\":\n",
    "#        return hi_en_translator(text, max_length=100)[0]['translation_text']\n",
    "#    else:\n",
    "#        return \"Sorry, I don't support that translation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function for the chatbot\n",
    "#def main():\n",
    "#    print(get_greeting())\n",
    "#    while True:\n",
    "        # Get input from the user\n",
    "#        user_input = input(\"You: \")\n",
    "\n",
    "        # Check if the user wants to quit\n",
    "#        if user_input.lower() in [\"bye\", \"goodbye\", \"exit\"]:\n",
    "#            print(get_goodbye())\n",
    "#            break\n",
    "\n",
    "        # Parse the user input for the source and target languages and the text to translate\n",
    "#        try:\n",
    "#            source_lang, target_lang, text = user_input.split(maxsplit=2)\n",
    "#        except ValueError:\n",
    "#            print(\"Sorry, I didn't understand that. Please try again.\")\n",
    "#            continue\n",
    "\n",
    "        # Translate the text\n",
    "#        translated_text = translate(text, source_lang, target_lang)\n",
    "\n",
    "        # Print the translated text\n",
    "#        print(f\"Bot: {translated_text}\")\n",
    "        \n",
    "#if __name__ == \"__main__\":\n",
    "#    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom built nlp translator\n",
    "\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.optim as optim\n",
    "#from torchtext.datasets import IMDB\n",
    "#from torchtext.data import Field, LabelField, BucketIterator\n",
    "\n",
    "# Define the text and label fields\n",
    "#TEXT = Field(tokenize='spacy', lower=True)\n",
    "#LABEL = LabelField(dtype=torch.float)\n",
    "\n",
    "# Load the IMDB dataset\n",
    "#train_data, test_data = IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "# Build the vocabulary\n",
    "#TEXT.build_vocab(train_data, max_size=10000, vectors='glove.6B.100d')\n",
    "#LABEL.build_vocab(train_data)\n",
    "\n",
    "# Define the model architecture\n",
    "#class SentimentClassifier(nn.Module):\n",
    "#    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "#        super().__init__()\n",
    "#        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "#        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, bidirectional=True, dropout=0.5)\n",
    "#        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "#        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "#    def forward(self, text):\n",
    "#        embedded = self.dropout(self.embedding(text))\n",
    "#        output, (hidden, cell) = self.lstm(embedded)\n",
    "#        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
    "#        return self.fc(hidden)\n",
    "\n",
    "# Instantiate the model\n",
    "#model = SentimentClassifier(len(TEXT.vocab), 100, 256, 1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "#optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Split the data into batches\n",
    "#BATCH_SIZE = 64\n",
    "#train_iterator, test_iterator = BucketIterator.splits((train_data, test_data), batch_size=BATCH_SIZE)\n",
    "\n",
    "# Train the model\n",
    "#N_EPOCHS = 10\n",
    "#for epoch in range(N_EPOCHS):\n",
    "#    train_loss = 0.0\n",
    "#    train_acc = 0.0\n",
    "#    model.train()\n",
    "#    for batch in train_iterator:\n",
    "#        optimizer.zero_grad()\n",
    "#        text = batch.text\n",
    "#        label = batch.label\n",
    "#        predictions = model(text).squeeze(1)\n",
    "#        loss = criterion(predictions, label)\n",
    "#        loss.backward()\n",
    "#        optimizer.step()\n",
    "#        train_loss += loss.item()\n",
    "#        train_acc += ((predictions > 0.5).float() == label).float().mean().item()\n",
    "#    train_loss /= len(train_iterator)\n",
    "#    train_acc /= len(train_iterator)\n",
    "#    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc:.3f}')\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "#    test_loss = 0.0\n",
    "#    test_acc = 0.0\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        for batch in test_iterator:\n",
    "#            text = batch.text\n",
    "#            label = batch.label\n",
    "#            predictions = model(text).squeeze(1)\n",
    "#            loss = criterion(predictions, label)\n",
    "#            test_loss += loss.item()\n",
    "#            test_acc += ((predictions > 0.5).float() == label).float().mean().item()\n",
    "#    test_loss /= len(test_iterator)\n",
    "#    test_acc /= len(test_iterator)\n",
    "#    print(f'Epoch: {epoch+1:02}, Test Loss: {test_loss:.3f}, Test Acc: {test_acc:.3f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
